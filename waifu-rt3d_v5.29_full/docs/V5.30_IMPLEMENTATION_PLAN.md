# v5.30 Implementation Plan - Detailed Code Specifications

**Date:** 2025-11-20
**Purpose:** Comprehensive rebuild guide for lost v5.30 backend features
**Current:** v5.29 backend (361 lines across 13 files)
**Target:** v5.30 backend (~561 lines with additions)

---

## Executive Summary

**What's Missing:**
- ASR (speech recognition) backend module (6 files, ~350 lines)
- Database schema v4 with characters table (1 file, ~70 lines)
- 10 new API endpoints in server.py (~200 lines)

**What Exists:**
- ✅ Frontend v5.30 features (`frontend/index_v2.html`, `frontend/viewer/lipsync.js`)
- ✅ v5.29 backend foundation (server, LLM, TTS adapters)

---

## Part 1: ASR Module Implementation

### File 1: `backend/asr/__init__.py`

**Purpose:** Package initialization
**Lines:** ~5

```python
"""
ASR (Automatic Speech Recognition) module.
Provides adapters for speech-to-text services.
"""

from .registry import get_asr_adapter

__all__ = ['get_asr_adapter']
```

---

### File 2: `backend/asr/adapters/__init__.py`

**Purpose:** Adapters package initialization
**Lines:** ~1

```python
# ASR adapters package
```

---

### File 3: `backend/asr/adapters/base.py`

**Purpose:** Base ASR adapter abstract class
**Lines:** ~80

**Key Components:**
1. Abstract base class `ASRAdapter`
2. Method: `__init__(self, config: dict)`
3. Abstract method: `async def transcribe(self, audio_file: bytes, language: str = "en") -> dict`
4. Return format: `{"text": str, "language": str, "confidence": float}`

**Code Structure:**
```python
from abc import ABC, abstractmethod
from typing import Dict, Optional

class ASRAdapter(ABC):
    """Base class for ASR (speech recognition) adapters."""

    def __init__(self, config: Dict):
        """
        Initialize ASR adapter.

        Args:
            config: Configuration dictionary with provider-specific settings
                   Keys: endpoint, api_key, model, language, etc.
        """
        self.config = config
        self.endpoint = config.get("endpoint", "")
        self.api_key = config.get("api_key", "")
        self.model = config.get("model", "whisper-1")
        self.language = config.get("language", "en")

    @abstractmethod
    async def transcribe(self, audio_bytes: bytes, language: Optional[str] = None) -> Dict:
        """
        Transcribe audio to text.

        Args:
            audio_bytes: Audio file as bytes (mp3, wav, webm, etc.)
            language: Optional language code override (default: self.language)

        Returns:
            {
                "text": str,          # Transcribed text
                "language": str,      # Detected/used language
                "confidence": float,  # 0.0-1.0, if available
                "duration": float,    # Audio duration in seconds, if available
            }

        Raises:
            Exception: If transcription fails
        """
        pass

    def validate_config(self) -> bool:
        """Validate adapter configuration. Override if needed."""
        return True
```

**Implementation Notes:**
- Similar structure to `backend/llm/adapters/base.py` and `backend/tts/adapters/base.py`
- Use async/await for I/O operations
- Return standardized dictionary format
- Include error handling in subclasses

---

### File 4: `backend/asr/adapters/whisper_api.py`

**Purpose:** OpenAI Whisper API adapter (cloud-based)
**Lines:** ~100

**Key Components:**
1. Class `WhisperAPIAdapter(ASRAdapter)`
2. Uses `requests` library for HTTP calls
3. Endpoint: `{endpoint}/audio/transcriptions`
4. Supports OpenAI API and compatible endpoints (e.g., LM Studio with Whisper)

**Code Structure:**
```python
import requests
import io
from typing import Dict, Optional
from .base import ASRAdapter

class WhisperAPIAdapter(ASRAdapter):
    """OpenAI Whisper API adapter for cloud-based transcription."""

    def __init__(self, config: Dict):
        super().__init__(config)
        # Ensure endpoint has correct format
        self.endpoint = self.endpoint.rstrip("/")
        if not self.endpoint.endswith("/audio/transcriptions"):
            self.endpoint = f"{self.endpoint}/audio/transcriptions"

    async def transcribe(self, audio_bytes: bytes, language: Optional[str] = None) -> Dict:
        """
        Transcribe audio using OpenAI Whisper API.

        API Endpoint: POST /v1/audio/transcriptions
        Documentation: https://platform.openai.com/docs/api-reference/audio
        """
        try:
            lang = language or self.language

            # Prepare multipart form data
            files = {
                'file': ('audio.webm', io.BytesIO(audio_bytes), 'audio/webm')
            }
            data = {
                'model': self.model,
                'language': lang,
                'response_format': 'json'  # Options: json, text, srt, vtt
            }
            headers = {
                'Authorization': f'Bearer {self.api_key}'
            }

            # Make API request
            response = requests.post(
                self.endpoint,
                files=files,
                data=data,
                headers=headers,
                timeout=30
            )
            response.raise_for_status()

            # Parse response
            result = response.json()
            return {
                "text": result.get("text", ""),
                "language": result.get("language", lang),
                "confidence": 1.0,  # Whisper API doesn't provide confidence
                "duration": result.get("duration", 0.0)
            }

        except requests.exceptions.RequestException as e:
            raise Exception(f"Whisper API request failed: {str(e)}")
        except Exception as e:
            raise Exception(f"Whisper API transcription failed: {str(e)}")

    def validate_config(self) -> bool:
        """Validate API key and endpoint."""
        if not self.api_key:
            raise ValueError("Whisper API requires 'api_key' in config")
        if not self.endpoint:
            raise ValueError("Whisper API requires 'endpoint' in config")
        return True
```

**Configuration Example:**
```json
{
  "asr": {
    "enabled": true,
    "provider": "whisper_api",
    "endpoint": "https://api.openai.com/v1",
    "api_key": "sk-...",
    "model": "whisper-1",
    "language": "en"
  }
}
```

---

### File 5: `backend/asr/adapters/whisper_local.py`

**Purpose:** Local Whisper.cpp adapter (fully offline)
**Lines:** ~120

**Key Components:**
1. Class `WhisperLocalAdapter(ASRAdapter)`
2. Calls local whisper.cpp server (typically on localhost)
3. Endpoint: `{endpoint}/inference` (whisper.cpp server endpoint)
4. Fully offline, privacy-focused

**Code Structure:**
```python
import requests
import io
from typing import Dict, Optional
from .base import ASRAdapter

class WhisperLocalAdapter(ASRAdapter):
    """Local Whisper.cpp adapter for offline transcription."""

    def __init__(self, config: Dict):
        super().__init__(config)
        # Default to localhost whisper.cpp server
        if not self.endpoint:
            self.endpoint = "http://127.0.0.1:8080"
        self.endpoint = self.endpoint.rstrip("/")

        # Whisper.cpp model name (e.g., "base.en", "small", "medium")
        self.model = config.get("model", "base.en")

    async def transcribe(self, audio_bytes: bytes, language: Optional[str] = None) -> Dict:
        """
        Transcribe audio using local Whisper.cpp server.

        Whisper.cpp Server: https://github.com/ggerganov/whisper.cpp
        Start server: ./server -m models/ggml-base.en.bin
        """
        try:
            lang = language or self.language

            # Whisper.cpp server expects multipart form
            files = {
                'file': ('audio.webm', io.BytesIO(audio_bytes), 'audio/webm')
            }
            data = {
                'language': lang,
                'response_format': 'json'
            }

            # Make request to local server
            response = requests.post(
                f"{self.endpoint}/inference",
                files=files,
                data=data,
                timeout=60  # Longer timeout for local processing
            )
            response.raise_for_status()

            # Parse response
            result = response.json()

            # Whisper.cpp returns different format
            if "text" in result:
                text = result["text"]
            elif "transcription" in result:
                text = result["transcription"]
            else:
                text = str(result)

            return {
                "text": text.strip(),
                "language": lang,
                "confidence": result.get("confidence", 0.95),
                "duration": 0.0
            }

        except requests.exceptions.ConnectionError:
            raise Exception(
                "Cannot connect to Whisper.cpp server. "
                "Is it running on {}?".format(self.endpoint)
            )
        except requests.exceptions.RequestException as e:
            raise Exception(f"Whisper.cpp request failed: {str(e)}")
        except Exception as e:
            raise Exception(f"Whisper.cpp transcription failed: {str(e)}")

    def validate_config(self) -> bool:
        """Check if Whisper.cpp server is accessible."""
        try:
            response = requests.get(self.endpoint, timeout=2)
            return response.status_code in [200, 404]  # 404 is ok for root
        except:
            return False
```

**Configuration Example:**
```json
{
  "asr": {
    "enabled": true,
    "provider": "whisper_local",
    "endpoint": "http://127.0.0.1:8080",
    "model": "base.en",
    "language": "en"
  }
}
```

**Setup Instructions:**
1. Download whisper.cpp: `git clone https://github.com/ggerganov/whisper.cpp`
2. Build: `make`
3. Download model: `bash ./models/download-ggml-model.sh base.en`
4. Start server: `./server -m models/ggml-base.en.bin`

---

### File 6: `backend/asr/registry.py`

**Purpose:** ASR adapter factory/registry
**Lines:** ~50

**Code Structure:**
```python
from typing import Dict, Optional
from .adapters.base import ASRAdapter
from .adapters.whisper_api import WhisperAPIAdapter
from .adapters.whisper_local import WhisperLocalAdapter

# Registry of available ASR adapters
ASR_ADAPTERS = {
    "whisper_api": WhisperAPIAdapter,
    "whisper_local": WhisperLocalAdapter,
}

def get_asr_adapter(config: Dict) -> Optional[ASRAdapter]:
    """
    Factory function to get ASR adapter instance.

    Args:
        config: ASR configuration dictionary
               Must include 'provider' key matching ASR_ADAPTERS keys

    Returns:
        ASRAdapter instance or None if ASR disabled

    Raises:
        ValueError: If provider not found or config invalid

    Example:
        config = {
            "enabled": True,
            "provider": "whisper_api",
            "endpoint": "https://api.openai.com/v1",
            "api_key": "sk-...",
            "model": "whisper-1"
        }
        adapter = get_asr_adapter(config)
        result = await adapter.transcribe(audio_bytes)
    """
    # Check if ASR is enabled
    if not config.get("enabled", False):
        return None

    # Get provider name
    provider = config.get("provider", "").lower()
    if not provider:
        raise ValueError("ASR config missing 'provider' key")

    # Get adapter class
    adapter_class = ASR_ADAPTERS.get(provider)
    if not adapter_class:
        available = ", ".join(ASR_ADAPTERS.keys())
        raise ValueError(
            f"Unknown ASR provider: '{provider}'. "
            f"Available: {available}"
        )

    # Create and validate adapter
    adapter = adapter_class(config)
    adapter.validate_config()

    return adapter
```

---

## Part 2: Database Schema v4

### File 7: `backend/db/schema_v4.sql`

**Purpose:** Add characters table, upgrade from v3
**Lines:** ~70

**Full Schema:**
```sql
PRAGMA journal_mode=WAL;

-- Sessions table (unchanged from v3)
CREATE TABLE IF NOT EXISTS sessions(
  id INTEGER PRIMARY KEY,
  title TEXT,
  created_ts REAL DEFAULT (strftime('%s','now'))
);

-- Messages table (unchanged from v3)
CREATE TABLE IF NOT EXISTS messages(
  id INTEGER PRIMARY KEY,
  session_id INTEGER NOT NULL,
  role TEXT CHECK(role IN ('user','assistant','system')) NOT NULL,
  text TEXT NOT NULL,
  ts REAL DEFAULT (strftime('%s','now')),
  FOREIGN KEY (session_id) REFERENCES sessions(id) ON DELETE CASCADE
);

-- Full-text search (unchanged from v3)
CREATE VIRTUAL TABLE IF NOT EXISTS messages_fts USING fts5(text, content='messages', content_rowid='id');

CREATE TRIGGER IF NOT EXISTS messages_ai AFTER INSERT ON messages BEGIN
  INSERT INTO messages_fts(rowid, text) VALUES (new.id, new.text);
END;

CREATE TRIGGER IF NOT EXISTS messages_ad AFTER DELETE ON messages BEGIN
  INSERT INTO messages_fts(messages_fts, rowid, text) VALUES('delete', old.id, old.text);
END;

-- NEW in v4: Characters table
CREATE TABLE IF NOT EXISTS characters(
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT NOT NULL,
  system_prompt TEXT NOT NULL,
  avatar_url TEXT,
  voice_id TEXT,
  tts_provider TEXT,
  personality_traits TEXT,  -- JSON array as text
  created_ts REAL DEFAULT (strftime('%s','now'))
);

-- NEW in v4: Add character_id to sessions (optional foreign key)
-- This requires migration for existing databases
-- For new installs, include in sessions table:
-- ALTER TABLE sessions ADD COLUMN character_id INTEGER REFERENCES characters(id);
-- But safer to keep separate for backward compatibility

-- NEW in v4: Insert default character
INSERT OR IGNORE INTO characters (id, name, system_prompt, avatar_url, personality_traits)
VALUES (
  1,
  'Friendly Assistant',
  'You are a friendly and helpful AI assistant with an enthusiastic personality. You enjoy chatting with users and helping them with their questions.',
  '/files/avatars/default.vrm',
  '["friendly", "helpful", "enthusiastic"]'
);

-- Schema version tracking
CREATE TABLE IF NOT EXISTS schema_version(
  version INTEGER PRIMARY KEY,
  applied_ts REAL DEFAULT (strftime('%s','now'))
);

INSERT OR REPLACE INTO schema_version (version) VALUES (4);
```

**Migration Notes:**
- v3 → v4 adds `characters` table
- Existing sessions/messages remain intact
- Default character (ID: 1) auto-created
- Future: Add `character_id` column to sessions table

---

## Part 3: Server.py Endpoint Additions

### Endpoint 1-5: Session Management

**Add to `backend/server.py` after existing `/api/chat` endpoint**

```python
# ==================== SESSION MANAGEMENT ====================

@app.get("/api/sessions")
def list_sessions():
    """
    List all chat sessions.

    Returns:
        {
          "sessions": [
            {"id": int, "title": str, "created_ts": float, "message_count": int},
            ...
          ]
        }
    """
    conn = db()
    cur = conn.cursor()
    cur.execute("""
        SELECT s.id, s.title, s.created_ts, COUNT(m.id) as msg_count
        FROM sessions s
        LEFT JOIN messages m ON s.id = m.session_id
        GROUP BY s.id
        ORDER BY s.created_ts DESC
    """)
    sessions = [
        {
            "id": row[0],
            "title": row[1] or f"Session {row[0]}",
            "created_ts": row[2],
            "message_count": row[3]
        }
        for row in cur.fetchall()
    ]
    conn.close()
    return {"sessions": sessions}


@app.post("/api/sessions")
async def create_session(req: Request):
    """
    Create a new chat session.

    Body:
        {"title": str}  # Optional, defaults to "New Session"

    Returns:
        {"id": int, "title": str, "created_ts": float}
    """
    body = await req.json()
    title = body.get("title", "New Session")

    conn = db()
    cur = conn.cursor()
    cur.execute("INSERT INTO sessions (title) VALUES (?)", (title,))
    session_id = cur.lastrowid
    cur.execute("SELECT created_ts FROM sessions WHERE id=?", (session_id,))
    created_ts = cur.fetchone()[0]
    conn.commit()
    conn.close()

    return {"id": session_id, "title": title, "created_ts": created_ts}


@app.put("/api/sessions/{session_id}")
async def update_session(session_id: int, req: Request):
    """
    Update session title.

    Body:
        {"title": str}

    Returns:
        {"ok": bool}
    """
    body = await req.json()
    title = body.get("title", "")

    if not title:
        raise HTTPException(400, "Title required")

    conn = db()
    cur = conn.cursor()
    cur.execute("UPDATE sessions SET title=? WHERE id=?", (title, session_id))
    conn.commit()
    conn.close()

    return {"ok": True}


@app.delete("/api/sessions/{session_id}")
def delete_session(session_id: int):
    """
    Delete session and all its messages.

    Returns:
        {"ok": bool}
    """
    conn = db()
    cur = conn.cursor()
    cur.execute("DELETE FROM messages WHERE session_id=?", (session_id,))
    cur.execute("DELETE FROM sessions WHERE id=?", (session_id,))
    conn.commit()
    conn.close()

    return {"ok": True}


@app.get("/api/sessions/{session_id}/messages")
def get_session_messages(session_id: int):
    """
    Get all messages for a session.

    Returns:
        {
          "messages": [
            {"id": int, "role": str, "text": str, "ts": float},
            ...
          ]
        }
    """
    conn = db()
    cur = conn.cursor()
    cur.execute("""
        SELECT id, role, text, ts
        FROM messages
        WHERE session_id=?
        ORDER BY id ASC
    """, (session_id,))
    messages = [
        {"id": row[0], "role": row[1], "text": row[2], "ts": row[3]}
        for row in cur.fetchall()
    ]
    conn.close()

    return {"messages": messages}
```

---

### Endpoint 6-9: Character Management

```python
# ==================== CHARACTER MANAGEMENT ====================

@app.get("/api/characters")
def list_characters():
    """
    List all characters.

    Returns:
        {
          "characters": [
            {
              "id": int,
              "name": str,
              "system_prompt": str,
              "avatar_url": str,
              "voice_id": str,
              "tts_provider": str,
              "personality_traits": list
            },
            ...
          ]
        }
    """
    conn = db()
    cur = conn.cursor()
    cur.execute("""
        SELECT id, name, system_prompt, avatar_url, voice_id, tts_provider, personality_traits
        FROM characters
        ORDER BY id ASC
    """)
    characters = []
    for row in cur.fetchall():
        import json
        traits = []
        try:
            if row[6]:
                traits = json.loads(row[6])
        except:
            pass

        characters.append({
            "id": row[0],
            "name": row[1],
            "system_prompt": row[2],
            "avatar_url": row[3],
            "voice_id": row[4],
            "tts_provider": row[5],
            "personality_traits": traits
        })
    conn.close()

    return {"characters": characters}


@app.post("/api/characters")
async def create_character(req: Request):
    """
    Create a new character.

    Body:
        {
          "name": str,
          "system_prompt": str,
          "avatar_url": str (optional),
          "voice_id": str (optional),
          "tts_provider": str (optional),
          "personality_traits": list (optional)
        }

    Returns:
        {"id": int, ...}
    """
    import json
    body = await req.json()

    name = body.get("name", "")
    system_prompt = body.get("system_prompt", "")

    if not name or not system_prompt:
        raise HTTPException(400, "name and system_prompt required")

    avatar_url = body.get("avatar_url", "")
    voice_id = body.get("voice_id", "")
    tts_provider = body.get("tts_provider", "")
    personality_traits = json.dumps(body.get("personality_traits", []))

    conn = db()
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO characters (name, system_prompt, avatar_url, voice_id, tts_provider, personality_traits)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (name, system_prompt, avatar_url, voice_id, tts_provider, personality_traits))
    char_id = cur.lastrowid
    conn.commit()
    conn.close()

    return {
        "id": char_id,
        "name": name,
        "system_prompt": system_prompt,
        "avatar_url": avatar_url,
        "voice_id": voice_id,
        "tts_provider": tts_provider,
        "personality_traits": json.loads(personality_traits)
    }


@app.put("/api/characters/{character_id}")
async def update_character(character_id: int, req: Request):
    """
    Update character details.

    Body: Same as create_character (all fields optional)

    Returns:
        {"ok": bool}
    """
    import json
    body = await req.json()

    conn = db()
    cur = conn.cursor()

    # Build dynamic UPDATE query based on provided fields
    updates = []
    params = []

    if "name" in body:
        updates.append("name=?")
        params.append(body["name"])
    if "system_prompt" in body:
        updates.append("system_prompt=?")
        params.append(body["system_prompt"])
    if "avatar_url" in body:
        updates.append("avatar_url=?")
        params.append(body["avatar_url"])
    if "voice_id" in body:
        updates.append("voice_id=?")
        params.append(body["voice_id"])
    if "tts_provider" in body:
        updates.append("tts_provider=?")
        params.append(body["tts_provider"])
    if "personality_traits" in body:
        updates.append("personality_traits=?")
        params.append(json.dumps(body["personality_traits"]))

    if not updates:
        raise HTTPException(400, "No fields to update")

    params.append(character_id)
    query = f"UPDATE characters SET {', '.join(updates)} WHERE id=?"

    cur.execute(query, params)
    conn.commit()
    conn.close()

    return {"ok": True}


@app.delete("/api/characters/{character_id}")
def delete_character(character_id: int):
    """
    Delete a character.

    Returns:
        {"ok": bool}
    """
    if character_id == 1:
        raise HTTPException(400, "Cannot delete default character")

    conn = db()
    cur = conn.cursor()
    cur.execute("DELETE FROM characters WHERE id=?", (character_id,))
    conn.commit()
    conn.close()

    return {"ok": True}
```

---

### Endpoint 10: ASR (Speech Recognition)

```python
# ==================== ASR (SPEECH RECOGNITION) ====================

@app.post("/api/asr")
async def transcribe_audio(file: UploadFile = File(...)):
    """
    Transcribe uploaded audio file to text.

    Form Data:
        file: Audio file (mp3, wav, webm, etc.)
        language: Optional language code (default: from config)

    Returns:
        {
          "text": str,
          "language": str,
          "confidence": float
        }
    """
    from .asr.registry import get_asr_adapter

    cfg = load_config()
    asr_config = cfg.get("asr", {})

    if not asr_config.get("enabled", False):
        raise HTTPException(400, "ASR not enabled in configuration")

    try:
        adapter = get_asr_adapter(asr_config)
        if not adapter:
            raise HTTPException(500, "ASR adapter not available")

        # Read audio file
        audio_bytes = await file.read()

        # Transcribe
        result = await adapter.transcribe(audio_bytes)

        return {
            "text": result["text"],
            "language": result.get("language", "unknown"),
            "confidence": result.get("confidence", 0.0)
        }

    except Exception as e:
        raise HTTPException(500, f"Transcription failed: {str(e)}")
```

---

### Update Chat Endpoint for Character Support

**Modify existing `/api/chat` endpoint:**

```python
@app.post("/api/chat")
async def chat(session_id: int = 1, character_id: int = 1, req: Request = None):
    """
    Send message and get AI response.

    Now supports character_id for custom system prompts and voices.
    """
    body = await req.json()
    text = body.get("text", "").strip()
    if not text:
        raise HTTPException(400, "text required")

    conn = db()
    cur = conn.cursor()
    cfg = load_config()

    # Get character info
    cur.execute("""
        SELECT system_prompt, voice_id, tts_provider
        FROM characters WHERE id=?
    """, (character_id,))
    char_row = cur.fetchone()

    if not char_row:
        # Fallback to default
        character_id = 1
        cur.execute("""
            SELECT system_prompt, voice_id, tts_provider
            FROM characters WHERE id=?
        """, (character_id,))
        char_row = cur.fetchone()

    character_system_prompt = char_row[0] if char_row else None
    character_voice_id = char_row[1] if char_row else None
    character_tts_provider = char_row[2] if char_row else None

    # Create session if needed
    cur.execute("INSERT OR IGNORE INTO sessions(id,title) VALUES (?,?)",
                (session_id, f"Session {session_id}"))

    # Save user message
    cur.execute("INSERT INTO messages(session_id,role,text) VALUES (?,?,?)",
                (session_id, "user", text))

    # Get conversation history
    limit = cfg.get("memory", {}).get("max_history", 12)
    cur.execute("""
        SELECT role,text FROM messages
        WHERE session_id=?
        ORDER BY id DESC
        LIMIT ?
    """, (session_id, limit))
    history = [{"role": r, "content": t} for r, t in reversed(cur.fetchall())]

    # Add character system prompt if available
    messages = []
    if character_system_prompt:
        messages.append({"role": "system", "content": character_system_prompt})
    messages.extend(history)

    # Get LLM response (existing code...)
    # ... rest of chat endpoint unchanged, but use character_voice_id and character_tts_provider for TTS
```

---

## Part 4: Preflight Updates

**Update `backend/preflight.py` to handle schema v4:**

Add schema migration logic:
```python
def upgrade_database_schema():
    """Upgrade database schema to latest version."""
    import sqlite3
    from pathlib import Path

    db_path = Path(__file__).parent / "storage" / "app.db"
    schema_v4 = Path(__file__).parent / "db" / "schema_v4.sql"

    if not schema_v4.exists():
        return  # v4 schema not available yet

    conn = sqlite3.connect(db_path)
    cur = conn.cursor()

    # Check current schema version
    try:
        cur.execute("SELECT version FROM schema_version ORDER BY version DESC LIMIT 1")
        current_version = cur.fetchone()
        current_version = current_version[0] if current_version else 3
    except:
        current_version = 3

    if current_version < 4:
        # Apply v4 schema
        schema_sql = schema_v4.read_text(encoding="utf-8")
        cur.executescript(schema_sql)
        conn.commit()
        print("✅ Database upgraded to schema v4")

    conn.close()
```

---

## Part 5: Configuration Updates

**Update `backend/config/app.json` example:**

```json
{
  "llm": {
    "endpoint": "http://127.0.0.1:1234/v1",
    "model": "local-model",
    "temperature": 0.7
  },
  "tts": {
    "enabled": false,
    "provider": "xtts_server"
  },
  "asr": {
    "enabled": false,
    "provider": "browser",
    "endpoint": "",
    "api_key": "",
    "model": "whisper-1",
    "language": "en"
  },
  "memory": {
    "max_history": 12
  }
}
```

---

## Summary Checklist

### Backend Files to Create (7 files):
- [ ] `backend/asr/__init__.py`
- [ ] `backend/asr/registry.py`
- [ ] `backend/asr/adapters/__init__.py`
- [ ] `backend/asr/adapters/base.py`
- [ ] `backend/asr/adapters/whisper_api.py`
- [ ] `backend/asr/adapters/whisper_local.py`
- [ ] `backend/db/schema_v4.sql`

### Backend Files to Modify (2 files):
- [ ] `backend/server.py` - Add 10 new endpoints (~200 lines)
- [ ] `backend/preflight.py` - Add schema migration (~30 lines)

### Configuration to Update (1 file):
- [ ] `backend/config/app.json` - Add ASR section

### Testing Checklist:
- [ ] Test session CRUD endpoints
- [ ] Test character CRUD endpoints
- [ ] Test ASR with Whisper API
- [ ] Test ASR with Whisper.cpp local
- [ ] Test character-aware chat
- [ ] Test database migration from v3 to v4
- [ ] Test frontend integration with new endpoints

---

**Total Additions:** ~1,240 lines of code across 10 files
**Estimated Implementation Time:** 4-6 hours
**Risk Level:** Low (well-defined, modular changes)

---

**Last Updated:** 2025-11-20
